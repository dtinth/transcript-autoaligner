"โอเคครับ ก็ สวัสดีทุกคนนะครับผม
ก็ขอต้อนรับเข้าสู่เซสชั่น"
"What I use and what I built to
make my life easier this year นะครับ"
"ก็ ที่ผมตั้งชื่อหัวข้อไว้แบบเนี้ย
เพราะว่าผมมีหลายๆเรื่อง"
ที่อยากจะมาเล่าให้ฟังมากๆเลยครับ
จนเลือกไม่ถูกเลยว่า จะพูดเกี่ยวกับเรื่องอะไร
ก็เลยกะว่าจะจับเอาเรื่องต่างๆ ที่ผมได้เรียนรู้ในปีเนี้ย
มามัดรวมกันเป็นเซสชั่นนี้นะครับ
ฉะนั้นเนี่ยก็อาจจะจับฉ่ายนิดนึงนะครับผม
โอเค คือในปีเนี้ยผมได้ทำหลายๆ โปรเจกต์ครับ
"ทั้งโปรเจกต์ที่ทำงาน โปรเจกต์งานอดิเรกด้วย
แล้วก็พบว่าในปีเนี้ย"
มันมีโปรเจกต์หลายตัวมาก ที่
"ถ้าเป็นผมเมื่อปีที่แล้วเนี่ย
ผมจะทำโปรเจกต์พวกนี้ไม่ได้เลย"
อ่า ซึ่งแน่นอนครับ
มันเกิดมาจาก
การมาของพวก Generative AI และ LLM เนาะ
ซึ่ง เอาจริงๆ อ่ะ ผมค่อนข้างสองจิตสองใจ
เกี่ยวกับหัวข้อนี้เหมือนกัน เพราะว่าผมรู้สึกว่าแบบ
"talk เกี่ยวกับเรื่อง AI ผมว่า
มันเยอะจนมันจะเกลื่อนแล้วอ่ะ"
แต่สำหรับผมน่ะ มัน impact workflow ต่างๆ ของผมมาก
ก็เลยคิดว่าอยากจะให้ session เนี้ย
เหมือนเป็นการตกตะกอนเรื่องที่ได้เรียนรู้ของตัวเองนะครับ
นอกจากนี้ครับ ปีนี้ผมได้เรียนรู้เครื่องมือหลายๆ ตัว
ที่มัน impact การทำงานของผมมาก ฉะนั้นก็เลย
"session เนี้ยก็เลยอยากจะมาแนะนำ
เครื่องมือต่างๆ ให้ได้รู้จักกันนะครับ"
ก็ขอแนะนำตัวก่อนละกันครับ
ผมชื่อไทนะครับ
ไท ปังสกุลยานนท์
ปัจจุบันทำงานอยู่ที่ Event Pop
ผมทำ community อยู่ชื่อว่า Creatorsgarten นะครับ
ซึ่งเดี๋ยวเราจะพูดกันถึงต่อไปนะครับ แล้วก็มีเว็บไซต์อยู่
dt.in.th นะครับ แล้ว
มี YouTube Channel ชื่อ dtinth นะครับ
ก็ไป subscribe กันได้นะครับ
โอเค
เข้าเรื่องดีกว่าครับ ก็สำหรับ session นี้
ผมจะพูดถึง project นึงเป็นหลักครับ
นั่นก็คือ เว็บไซต์ของ creatorsgarten.org ครับ
ก็จะเป็นเว็บของกลุ่ม Creatorsgarten
แปลตรงๆ ก็คือสวนนักสร้างเนี่ยแหละ ก็
กลุ่มเราเนี่ย จัด event กันหลากหลายรูปแบบมาก
ไม่ว่าจะเป็นพวก event tech
หรือแบบสายศิลปะ
คณิตศาสตร์ วิทยาศาสตร์
การศึกษา
การเงิน
รวมถึงเรื่องความรักด้วย
ซึ่งทั้งเนี้ย ก็ขึ้นอยู่กับว่า
เจ้าของงานเนี่ย อยากจะจัด event แบบไหนเนาะ
ซึ่ง แต่ละ event เนี่ย ก็จะลีดโดยคนละคนกันนะครับ
"แล้วก็ จริงๆ อ่ะ เราไม่ได้ fix นะ
ว่าจะเป็น event หมวดไหน"
เราจะมีความ เรียกว่า anti-discipline นิดหน่อยก็คือ
พยายามเอาหลายๆ เรื่องมายำรวมกันน่ะครับ
"แล้วก็พวกเราไม่ได้มีโครงสร้าง
หรือแผนงานที่ตายตัวครับ"
"ก็คือแบบไม่ได้มีคณะกรรมการ
หรือไม่ได้มี target อะไรเลย"
ว่าปีนึงจะต้องจัดกี่งานนะ แต่ว่า
เวลาที่ใครก็ตามเนี่ยอยากจะจัด event เนี่ย
เราก็มาคุยกัน ถ้าเขาพร้อมที่จะเป็น lead
เราก็ช่วยให้งานมันเกิดขึ้นมานะครับ
"โดยกลุ่มเราเนี่ยจะมีพวก
shared resource ต่างๆ ครับ"
เพื่อให้สามารถจัดงานได้ง่ายขึ้น
ไม่ต้องเริ่มจากศูนย์น่ะแหละ
ก็คือเรามีเว็บไซต์ มี account Eventpop
มีเพื่อนๆ ที่มาช่วยเป็น volunteer ในงานนะครับ แล้วก็
มีพวกเครื่องมืออุปกรณ์
มีแพลตฟอร์ม social มี team live นะครับ
อย่างรอบเนี้ย เราก็จ้าง LiveTube มาช่วยนะครับ
"แต่ว่าพวกงานที่เราไม่ค่อยมีงบ
เราก็ทำ live กันเองนะครับ"
เราก็มีทีมอยู่
แล้วก็มีแพลตฟอร์ม social นะครับ
รวมถึง channel YouTube ครับ
ซึ่งอย่างนึงที่ผมได้ทำในปีเนี้ย ก็คือ
"section วิดีโอนะครับ บนเว็บไซต์ครับ
ก็จะเป็นหน้าที่รวบรวมวิดีโอจาก session ต่างๆ"
ที่เราอัปโหลดขึ้น YouTube นะครับ
"แต่ว่าเรามีการจัด filter ต่างๆ
เพื่อให้สามารถหาวิดีโอของแต่ละงาน"
"แล้วก็หาวิดีโอของแต่ละ speaker ได้ด้วย
ฉะนั้น speaker แต่ละคนเนี่ย ก็จะมี"
"เหมือนเป็นหน้าเว็บของตัวเอง
ที่รวบรวมหัวข้อของ speaker คนนั้นอยู่นะครับ"

"โอเค คราวเนี้ย แต่ละคลิปนะครับ
สิ่งนึงที่ผมอยากให้มันมีเนี่ย ก็คือ"
"อยากจะให้แต่ละคลิปเนี่ย มีบทถอดคำพูด
แล้วก็มี subtitle เนาะ"
"เพราะว่า บางทีอ่ะ เวลาผมดู YouTube ข้างนอกนะ
บางทีก็ไม่อยากเปิดเสียง"
"แล้วก็ไม่อยากใส่หูฟัง ก็คิดว่าคงจะดี
ถ้ามันมี subtitle ให้อ่าน"
ปกติคลิปภาษาอังกฤษเนี่ย ทำ auto sub
"อ่า มัน มันมี autogenerated caption อยู่แล้ว
ซึ่งแม่นยำพอสมควร แต่พอเป็นภาษาไทยเนี่ย"
"เมื่อก่อน YouTube ไม่มี ตอนนี้มีเนาะ
แต่ว่าสำหรับพวก tech talk"
"ที่มันมีเนื้อหาที่เป็น technical
มีคำศัพท์เทคนิคเยอะอ่ะ มันยังไม่แม่นยำพอ"
ฉะนั้นเนี่ย พอเรามีบทถอดคำพูดอยู่บนหน้าเว็บนะ
"เนื้อหามันจะครบถ้วนขึ้น
แล้วมันก็จะเป็นผลดีต่อ SEO ใช่มั้ย"
search engine optimization เนาะ
นอกจากบทถอดคำพูดแล้วเนี่ย ก็คือบางวิดีโอมันก็ยาว
"ก็จะอยากให้มันมีการแบ่งเนื้อหา
เป็น chapter ต่างๆ นะครับ"
"เพื่อให้ทุกคนสามารถเข้ามาดูแล้วก็
เห็นภาพรวมเกี่ยวกับเนื้อหาก่อนที่จะเข้าไปดูจริงๆได้นะครับ"

ฉะนั้นเนี่ย โปรเจกต์เนี้ย ก็อาจจะเฉพาะทางนิดนึง
"ก็เชื่อว่าหลายๆคนที่ฟัง session นี้ก็อาจจะไม่ได้สนใจ
เรื่องการทำ subtitle มากซักเท่าไหร่เนาะ"
"แต่สำหรับผมเนี่ยมันเป็นอะไรที่แบบ
ผมได้เรียนรู้เยอะแบบ เยอะมากๆ"
"อืม ก็เลยอยากจะขอใช้โปรเจกต์เนี้ย
เป็นตัวอย่างเพื่อถอดบทเรียนออกมาครับ"

"ก่อนหน้านี้ ผมก็ทำ subtitle ให้คลิปใน
channel YouTube ตัวเองนะครับ"
"ก็คือทำแบบ manual เลย
ฟังเอง ถอดคำพูดเอง ทำ subtitle เอง"
"เพราะมันจะมีโปรแกรมฟรีๆ เช่น Amara
หรือ Happy Scribe เนี่ย ก็คือ ใช้ฟรี"
"support ลิงก์ YouTube ด้วย
แล้วก็มีคีย์ลัดเยอะมาก สะดวกมากๆ"
แต่เวลาทำ subtitle ทีเนี่ย คือแบบ
เหนื่อยมาก จากที่เคยลองทำนะครับ
คลิป 10 นาที ผมใช้เวลาทำประมาณชั่วโมงนึง
ฉะนั้น ถ้าเรามีวิดีโอคอนเทนต์ 1 ชั่วโมงเนี่ย
ก็คูณเข้าไปครับ
ก็อาจจะใช้เวลาประมาณ 6-8 ชั่วโมงครับ
"ซึ่งผมว่าผมก็ใช้คอมพิวเตอร์คล่องแล้วนะ
พิมพ์ ก็คิดว่าก็พิมพ์เร็วใช้ได้"
แต่ก็ยังใช้เวลาเยอะมากๆ อยู่ดี
แต่ข้อดีก็คือ ไม่ต้องจ่ายตังค์ ใช่มั้ย
ทำเองก็ฟรีใช่มั้ยฮะ
"แต่พอผมทำคลิปนึงเสร็จเนี่ย
คือผมแทบจะเบิร์นเอาท์ไปเลย"
และนี่แค่วิดีโอของตัวเองนะครับ
"ถ้าเป็นวิดีโอของคนอื่นเนี่ย ผมก็คงแบบ
ไม่ได้มีไฟจะมาทำให้ขนาดนั้น"
ถ้าเกิดมันต้องใช้ effort เยอะขนาดนี้ครับ
"อีกทางเลือกนึงก็คือ เราอาจจะจ้างมืออาชีพ
มาทำ subtitle ให้เรานะครับ"
"ซึ่งเท่าที่ผมเคยลองหาดูเนี่ย ก็จะคิดเรตเป็นนาทีครับ
ซึ่งถ้าเราตีเป็นชั่วโมงเนี่ย เท่าที่ผมลองหาดูนะ"
ราคาก็เป็นหลักพันนะครับ
ซึ่ง จากที่ผมเคยลองทำ subtitle ด้วยตัวเอง ก็คิดว่าแบบ
เออ มันสมเหตุสมผลละ ราคาแบบเนี้ย
เพราะผมทำ subtitle เองทีคือเลือดตาแทบกระเด็น
แถมถ้าเป็นการทำ subtitle มืออาชีพนะ
นี่ครับ มีกฎเต็มไปหมดเลย
"มี guideline เรื่องการทำ subtitle ไปหมดเลย
ว่าจะเอาอะไรไว้ตรงไหน"
เขียน สะกดตัวเลขยังไงอะไรพวกเนี้ย
อันนี้ที่โชว์ให้ดูนะครับเป็น guideline ของ Netflix นะครับ
โอเค ซึ่งงาน meetup ของเราเนี่ย
ส่วนมากก็จะมีคอนเทนต์ประมาณ 2-3 ชั่วโมง
งบก็ไม่น่าจะพอ หรือเอาจริงๆ น่ะ
คือเราจัดงานฟรี งาน meetup ส่วนมากเนี่ย
ฉะนั้นเราไม่มีงบอะไรเลยด้วยซ้ำนะครับ
"เอาจริงๆ เราไม่ได้ต้องการ subtitle
ระดับ professional ระดับ Netflix ขนาดนั้นนะครับ"
แค่มีบทถอดคำพูดไว้ให้อ่านได้เนี่ย
ผมว่าก็ดีเกินพอแล้ว
ฉะนั้นเนี่ยในช่วง ปีสองปีที่ผ่านมา
"ผมเลยศึกษาเกี่ยวกับเครื่องมือต่างๆ
ที่จะมาช่วยกระบวนการนี้ครับ"
แต่เดี๋ยวผมจะขอพักโปรเจกต์นี้ไว้ก่อน
ผมจะขอสลับไปพูดเกี่ยวกับเรื่อง
Large Language Model ก่อนนะครับ
ก็ปัจจุบันเนี่ย ตัวที่ได้รับความนิยมสูงสุดก็นี่เนาะ
ChatGPT Claude Gemini เนาะ
ก็จะมีคนมาถามผมบ่อยๆ ว่า
ถ้าเลือกได้แค่ตัวเดียวเนี่ย จะจ่ายเงินให้ตัวไหนดี
"เพราะแต่ละตัวเนี่ย 20 เหรียญต่อเดือนทั้งนั้นเลย
ใช่มั้ย ถ้าอยากใช้ทั้ง 3 ตัวก็ 60 ใช่มั้ย ไม่รู้จะคุ้มมั้ย"

"ดังนั้นถ้าให้เลือกเนี่ย จะจ่ายตัวไหนดี
ซึ่งผมให้คำตอบไม่ได้เลยครับ"
"เพราะว่าแต่ละตัวเนี่ย
มีข้อดีข้อเสียต่างกันหมดเลย"
ฉะนั้นเนี่ยผมเลยต้องใช้ทุกตัว
"แต่ขณะเดียวกันเนี่ย ผมก็ไม่ได้จ่ายเงิน
20 เหรียญต่อเดือนให้แอปไหนซักแอปเลย"
ทำยังไงครับ
ก็คือพวกแอป ChatGPT Claude Gemini เนี่ย
ผมเรียกว่าเป็น service
"เป็นบริการที่ออกแบบมาให้คนทั่วไป
หรือคนที่ไม่ได้มีความรู้ด้านเทคนิคเนี่ย"
สามารถใช้งานได้ง่าย
"ซึ่ง service พวกเนี้ย ถ้าอยากจะใช้เวอร์ชั่นที่แบบ
ฉลาดๆ ฟีเจอร์เยอะๆเนี่ย ก็ใช่มั้ย"
เหมาจ่ายรายเดือน 20 เหรียญนะครับ
"แต่บริษัทพวกเนี้ย ก็ได้พัฒนาโมเดล
ที่เปิดให้นักพัฒนา"
"หรือคนที่มีความสามารถใช้งานมันเป็นเนี่ย
ก็สามารถเข้าไปใช้งานได้ตรงๆ ด้วย"
"โดยโมเดลพวกเนี้ย ก็จะคิดราคา
ตามปริมาณที่ใช้งานจริงนะครับ"
เรียกว่าคิดเป็นโทเคนน่ะ ซึ่ง
ถ้าใช้น้อยก็จ่ายน้อย ใช้เยอะก็จ่ายเยอะครับ
ซึ่งเวลาผมเอาไอ้เนี่ยไปแนะนำ ก็จะมีคนบอกว่า
"กลัวว่าถ้าใช้เยอะเกินแล้ว
สุดท้ายมันจะเสียตังค์เยอะกว่าเหมาจ่าย"
ซึ่งจากประสบการณ์ของผมนะครับ คือ
ผมใช้เองคนเดียวทั้ง 3 เจ้า—
อันนี้ผมเอา billing ของตัวเองมาให้ดูนะครับ
ก็ไม่เคยใช้ร่วมกันเกิน 50 เหรียญเลย
"แล้วส่วนมากอ่ะ ผมจะใช้ไม่ถึง
เดือนละ 20 เหรียญด้วยซ้ำ"
ฉะนั้นเนี่ย ก็สามารถไปลองเล่นกันดูได้นะครับ
"อ่า บางเจ้าก็จะเป็นแบบเติมเงิน
ก็คือไม่ต้องกลัวว่าจะโดน bill shock นะ"
แล้วก็บางเจ้าเนี่ยก็เป็นเก็บตังค์รายเดือนนะครับ
เราตั้ง budget alert ได้นะครับ
"แล้วเราสามารถใช้งานโมเดลพวกเนี้ย
โดยไม่ต้องเขียนโค้ดเลยด้วย"
ก็คือเข้าไปใช้งานที่คอนโซลของแต่ละเจ้านะครับ
"อย่างในรูปด้านซ้ายเนี่ยนะครับคือ ChatGPT
ส่วนด้านขวาคือ OpenAI platform ครับ"
จะเห็นว่าการใช้งานเนี่ยคล้ายๆ กันเลย
ก็คือเป็นการแชทใช่มั้ย
"แล้วใน OpenAI platform เนี่ยจะเห็นว่ามันมี
setting ต่างๆ ให้เลือกเยอะขึ้นด้วยนะครับ"
"อันนี้ก็คล้ายๆ กันครับ ด้านซ้าย Claude
ด้านขวา Anthropic Console"
"แล้วก็อันนี้ ด้านซ้าย Gemini
ด้านขวา Google AI Studio นะครับ"

"ก็อย่างที่บอกไปนะครับ แต่ละโมเดลเนี่ย
จะมีจุดเด่นจุดด้อยแตกต่างกันออกไป"
ฉะนั้นถ้าเราอยากจะรู้นะครับ เราต้องทำยังไง
ต้องทดสอบถูกไหมครับ ต้องทดลอง
โอเค ตัวอย่างนี้นะครับ
"ผมต้องการจะทดสอบความสามารถ
ด้านภาษาไทยของโมเดลแต่ละตัว"
"ผมเลยเอาเรื่องเล่าภาษาอังกฤษเรื่องนึง
เกี่ยวกับ Yak shaving นะครับ เอามาแปะ"
แล้วก็เขียนในคำสั่งใน prompt ว่า
“ช่วยเล่าเรื่องนี้เป็นภาษาไทยให้หน่อย”
เสร็จแล้วผมก็ลองเทียบผลลัพธ์ดู
อันนี้ผมจะลองเริ่มจากตัวฟรีก่อนนะ
ผมพบว่าทั้ง Claude กับ ChatGPT เนี่ย
แปลชื่อเรื่องได้อย่างถูกต้อง ก็คือ
Yak shaving อ่ะ ก็แปลว่าการโกนขนจามรี
แต่ Gemini เนี่ย ดันแปลเป็น
การเลื่อยขนยักษ์
"ซึ่ง เอาจริงๆ เนี่ย Gemini
มันแปลมาหลายแบบมาก"
"แต่ไม่ว่าผมจะลองกี่ครั้ง เหมือนมันก็ไม่รู้สักทีว่า
Yak เนี่ย ในภาษาอังกฤษมันคือ จามรี นะครับ"
"ฉะนั้นเนี่ย พอผมเอาตัวฟรีมาเทียบกันเนี่ย
แล้วเห็นผลลัพธ์ออกมาแบบนี้แล้ว คือแบบ"
"ใครมันจะไปกล้าจ่ายตังค์ให้
Gemini Advance ใช่มั้ย"
อืม วันก่อนผมลองคุยกับ Gemini ดูนะครับว่า
“Can you speak Thai?” พูดภาษาไทยได้มั้ย?
คิดว่ามันตอบว่าอะไรครับ
เอ่อ… ไม่?
มันตอบว่า…
อันยองฮาเซโย แต่ตอบเป็นภาษาไทยนะ
แล้วก็บอกว่า
พูดภาษาไทยไม่ได้… แต่ตอบเป็นภาษาไทย
ผมก็ไม่รู้ทำไมมันมึนขนาดนี้
อ่า… ฉะนั้นเนี่ย… โอเค… ไม่เป็นไร
"เมื่อกี้อาจจะไม่แฟร์เพราะว่า
เราเอาตัวฟรีมาเทียบกันเนาะ"
"อ่ะ ไหน เราลองจ่ายตังค์
แล้วใช้ตัวที่ดีที่สุดของแต่ละเจ้าดูบ้าง"
"ผมก็ลองทำแบบเดิมครับ
รอบนี้ไปใช้คอนโซลแต่ละตัวแทนเนาะ"
รอบนี้ทั้ง 3 โมเดล แปลถูกต้องแล้วนะครับ
เราก็ต้องเอาผลลัพธ์มากางดู
ว่าตัวไหนแปลออกมาได้ดีที่สุด
"ซึ่งผมพบว่ารอบเนี้ย GPT-4o กับ Claude เนี่ย
มันจะแปลเรื่องราวแบบตรงตัวมากๆ"
แต่ Gemini เนี่ย ผมว่ามันน่าสนใจกว่าตัวอื่น
"เพราะว่า ผมลองอ่านแล้วอ่ะ รู้สึกเหมือน
มันพยายามทำให้เนื้อเรื่องอ่ะ"
มันเข้ากับบริบทคนไทยด้วย อย่างเช่น
"wax the car เนี่ย ก็ ลงแว็กซ์รถ
Gemini ก็เปลี่ยนเป็นล้างรถ อ่า ใช่"
โฮมดีโป มันก็เปลี่ยนเป็นโฮมโปร
"หรือสะพานแท็บแปนซี
ก็กลายเป็นสะพานพระรามแปด"
ใช่มั้ย อ่า อีกเรื่องนึงที่ผมพบคือ
"ภาษาอังกฤษเนี่ย มันเป็นภาษาที่
แทบทุกประโยคอ่ะ มันจะต้องมี subject"
มีประธาน
ฉะนั้นเนี่ย เวลาพอแปลเป็นภาษาไทยตรงๆ
"มันจะทื่อๆ แบบ… “ฉันสามารถยืม
EZPass ของเพื่อนบ้านได้”"
เออ มันจะทื่อนิดนึง
"แต่ Gemini เนี่ย ตัดคำว่าฉันออกไป
มันทำให้ฟังดูเป็นธรรมชาติมากขึ้นนะครับ"
แถมรู้ด้วยว่า บ๊อบเนี่ย น่าจะเป็นผู้ชาย
ก็เลยเรียกว่า ลุงบ๊อบ
"เอาจริงๆ ผมลองหลายรอบ
บางทีมันก็เปลี่ยนชื่อลุงบ๊อบ"
กลายเป็นลุงสมศักดิ์ให้เลย
หรือบางทีมันก็แปลตรงตัวนะ
แต่ว่า ฟีเจอร์เนี้ย เป็นฟีเจอร์ที่
ผมไม่เคยเห็น Claude หรือ GPT ทำให้นะครับ
"ฉะนั้นสำหรับโจทย์ “ช่วยเล่าเรื่อง
เป็นภาษาไทยให้หน่อย” เนี่ย"
ก็พบว่า โมเดลเสียเงินเนี่ย
ตัว Gemini Pro เนี่ยจะชนะขาดไปเลยนะครับ
"เพราะฉะนั้นเนี่ย เรื่องที่ผมอยากฝากไว้
ให้ทุกคนลองก็คือ เดี๋ยวเนี้ยมันง่ายมากๆ"
ที่เราจะไปลองเล่นกับ AI โมเดลต่างๆ เนาะ
ตอนนี้แต่ละเจ้าก็ ต่างแข่งกันทำให้ของตัวเอง
ใช้งานง่ายมากที่สุด ราคาถูกที่สุด
ก็แนะนำให้ลองกันเยอะๆ นะครับ
"ฉะนั้นเนี่ย ถ้าเราใช้มันผ่านคอนโซล
เราก็ไม่ต้องจ่าย flat rate ละ"
"ก็ไปจ่ายตามจริงเนาะ แล้วก็สามารถตั้งค่า
ปรับแต่งอะไรต่างๆ ได้เยอะกว่าด้วย"
"แถมอีกฟีเจอร์นึงครับ ผมชอบมากๆ คือ
เราสามารถแก้คำตอบของโมเดลได้ด้วยเนาะ"
"อ่า อย่างเช่น อันเนี้ยครับ
ผมใช้ Google AI Studio เนาะ"
"ช่วยแปลข้อความจากภาษาอังกฤษ
มาเป็นภาษาไทยให้หน่อย"
"อ่า ผมว่ามันก็แปลดีอยู่นะ แต่ผมไม่ชอบ
ที่มันแปลคำว่า endpoint เป็น “จุดปลาย”"
เพราะรู้สึกไม่มีใครใช้กันน่ะ
"คือแบบ เออ “ถ้าจะต่ออายุโทเค็นเนี่ย
เราต้องไปเรียกจุดปลายไหน”"
ก็ไม่มีใครพูดแบบนั้นกันใช่มั้ย
อืม ซึ่ง ถ้าพวก Gemini หรือ ChatGPT เนี่ย
"ปกติเราไม่สามารถแก้ไขข้อความ
ที่โมเดลมันตอบมาได้"
"เราก็ต้องไปแก้ prompt ของเรา
หรือไม่ก็คุยกับโมเดลต่อว่า"
เฮ้ย ช่วยไม่แปลคำนี้หน่อยได้ไหม
"ไม่งั้นมันก็จะใช้คำว่า จุดปลาย จุดปลาย
จุดปลาย ไปเรื่อยๆ นะครับ"
แต่ Google AI Studio เนี่ย
"เรา edit คำตอบของโมเดลได้เลย ผมก็
จัดการแก้เป็น endpoint แล้วก็"
"มากด rerun ข้างล่างนะครับ
มันก็เลิกแปล endpoint เป็นจุดปลายให้ละ"
"เราสามารถควบคุม การทำงานของโมเดล
โดยการแก้ไขคำตอบมันได้ด้วยนะครับ"
แต่ว่าพวก service สำเร็จรูปเนี่ยไม่ใช่ว่ามันไม่ดีนะ

ผมว่ามันก็มีข้อดีมากๆ อย่างนึง
"คือมัน integrate อะไรต่างๆ
ไว้ให้เราใช้งานได้สะดวกนะครับ"
อย่างเช่นอันเนี้ยครับ ผมชอบมากเลยก็คือ
"เวลาผมเห็นคลิป YouTube
แต่ไม่มีเวลาเข้าไปดูอ่ะ"
ผมก็ก๊อบลิงก์ YouTube มาแปะ
แล้วก็บอกให้ Gemini สรุปให้หน่อย
อันเนี้ย Google AI Studio ทำไม่ได้นะครับ
ต้องเป็นตัวแอป Gemini นะครับ
"ซึ่งเวิร์กมาก โดยเฉพาะพวกคลิปที่มันแบบ
มีความ clickbait อ่ะ"
หรือพวกคลิปยาวๆ แต่ไม่เข้าเนื้อหาสักทีอ่ะ
อ่า ก็จะโยนให้ Gemini ช่วยสรุปให้ก่อนนะครับ
"แล้วค่อยตัดสินใจนะครับว่าจะดูดีไหม
อะไรประมาณนี้นะครับ ซึ่งสะดวกมาก"
แล้วที่ผมชอบคือ เอ่อ มันดีทั้งสองฝ่ายนะ
"ก็คือ พอเราให้ Gemini สรุปให้เนี่ย
มันจะไปนับวิวใน YouTube ให้ด้วย"
ซึ่งถ้าใครยังไม่เคยลองกับคอนโซลพวกนี้เลยนะครับ
ผมแนะนำให้ลอง Google AI Studio ดูก่อนเนาะ
"เพราะมันฟรี สามารถเริ่มใช้งานได้เลย
โดยไม่ต้องผูกบัตรนะครับ"
โอเค
เดี๋ยวผมจะพาไปดูอีกโปรเจกต์นึงที่ผมเคยอยากทำมานาน
แล้วเพิ่งมาได้ทำปีนี้นะครับ
คือเดี๋ยวเนี้ย โทรศัพท์ iPhone Android นะ
เราสามารถใช้ฟังก์ชันสแกนเอกสารได้แล้วใช่มั้ย
มันก็จะได้เป็นไฟล์ PDF นะฮะ
แล้วสมัยก่อนเนี่ย ผมเคยอยากทำระบบที่แบบ
"เราถ่ายรูปใบเสร็จอ่ะ เราให้มันเซฟใส่ database ให้
เราจะได้คำนวณรายรับรายจ่ายเราได้ง่ายขึ้น"
"นะครับ อ่า ก่อนหน้าเนี้ย
ผมเคยลองพยายามทำเนาะ"
โดยใช้ Google Cloud Vision API นะครับ
"ซึ่งหน้าที่ของมันเนี่ย คือมันจะแกะข้อความ
ออกจากไฟล์รูป ก็คือเรียกว่าเป็นการทำ"
"OCR นะครับ แล้วเราจะได้
เป็นไฟล์ JSON แบบเนี้ย"
"ที่บอกว่า ตัวอักษรอะไรอยู่ตรงไหนบ้าง
ซึ่งผลลัพธ์มันแม่นมากๆนะครับ"
"แต่การจะเอาข้อมูลเนี้ยไปใช้ก็คือ
ค่อนข้าง challenge นะครับ"
"เพราะว่าเราต้อง match ว่า
ข้อความไหนตรงกับตัวเลขไหน"
แถมบางทีเนี่ย
"มันดันจับเอาบล็อกหลายๆ บล็อกอ่ะ
มารวมกันเป็นบล็อกเดียวด้วย"
"ฉะนั้นสำหรับผมเนี่ย มันแทบจะเป็นไปไม่ได้เลย
ที่จะเขียนโค้ดให้มันประมวลผลได้ทุกกรณี"
ผมก็เลยพับโปรเจกต์นี้ไว้ก่อนนะครับ
"โอเค ทีเนี้ย พอปีเนี้ย ผมมารู้จัก
Google AI Studio นะ"
ก็ได้ลองเอาโปรเจกต์นี้กลับมาทำใหม่
"ก็คือ เขียน prompt
อัปโหลด PDF ไฟล์ ขึ้นไปนะครับ"
แล้วก็กดปุ่ม run นะครับ
แล้วก็จะได้ผลลัพธ์หน้าตาประมาณนี้
คือมันทำเป็นตารางให้เลยนะครับ
ผมก็อปไปใส่ใน Google Sheets ได้เลยนะครับ
นอกจากเนี้ย มีตัวเลือก JSON mode ด้วย
"พอเรากด เราก็จะได้ data
เป็น JSON ออกมานะครับ"
"แล้วถ้าเรากด get code ข้างบนนะครับ
เราก็จะได้โค้ดที่เราเอาไปใช้ integrate ต่อ"
กับระบบของเราได้นะครับ
"ฉะนั้นเนี่ย ตอนเนี้ยผมก็สามารถดึงข้อมูล
ออกจากไฟล์ใบเสร็จที่สแกนออกมาได้แล้วนะครับ"
โดยที่ผมยังไม่ได้เขียนโค้ดอะไรเลยนะครับ
"แต่เวลาเอาข้อมูลจากโมเดลเนี้ยไปใช้
ก็อย่าลืมตรวจสอบความถูกต้องนะครับ"
อันนี้ผมลองตรวจสอบตัวเลขละ ถูกต้องหมด
"แต่ว่าจะเห็นว่าด้านบนเนี่ย เอ่อ
ชื่อร้านอาหารมันก็สะกดผิดเนาะ"
หรือข้าวไข่ข้นมันก็กลายเป็นข้าวไข่ขัน
อะไรแบบเนี้ย
ครับ ก็จะเห็นว่าพอเราใช้คอนโซลพวกนี้เป็นเนี่ย
มันทำให้เราทำอะไรได้เยอะขึ้นเลย
มันลดงาน manual ผมเยอะมาก
"แต่คอนโซลพวกเนี้ย บางที
มันก็ใช้งานไม่ค่อยสะดวกครับ"
"ฉะนั้นยิ่งถ้าใช้งานบนมือถือเนี่ย
คอนโซลบางตัวเนี่ย คือมันจะบอกเลย"
ว่าเราไม่ support มือถือให้ไปเปิดใน—
คือไล่ไปเปิดใน desktop อ่ะ
อ่า ก็จะมาแนะนำเครื่องมือตัวนึงนะครับ
ที่ผมใช้บ่อยมาก
ชื่อว่า Open Web UI นะครับ
"หน้าที่ของมันคือ เหมือนเป็น front end
สำหรับ API ของ OpenAI นะครับ"
คือเราสามารถใช้งานมันแทน ChatGPT ได้
"ฟังก์ชัน ฟีเจอร์ทั้งหมดเนี่ย
อาจจะไม่เหมือนกันเนาะ"
"แต่ว่าอย่างน้อยเราก็ไม่ต้องจ่าย
$20/เดือน ให้ ChatGPT Pro"
เราก็ไปเอา API key ของ OpenAI มาเสียบ
แล้วเราก็ใช้ตัวนี้แทนนะครับ
"แอปเนี้ย เป็น open source แล้วก็
มี image Docker พร้อมใช้ นะครับ"
"ก็คือเป็นแบบ self-hosted
คือถ้าเราอยากจะใช้เนี่ย"
เราก็ต้องเอา image Docker มา deploy เอง
หรือจะโคลนโค้ดมารันเองเลย ก็ได้เหมือนกันนะ
โดยตัว Open Web UI เนี่ย
มันจะสามารถ ทำงานกับ service ต่างๆ
"ที่มี API endpoint หน้าตาเหมือนของ
OpenAI ได้นะครับ"
"ฉะนั้นถ้าเราอยากจะใช้งานกับโมเดลอื่นๆ
อย่าง Claude หรือ Gemini ล่ะ ทำยังไงนะครับ"
ก็จะมีซอฟต์แวร์ตัวนึงชื่อ LiteLLM นะครับ
ตัวเนี้ย เป็น proxy ที่ implement API
ที่จุดปลายต่างๆ มันเหมือนของ OpenAI อะครับ
(แปลกใช่มั้ย ใช้คำว่าจุดปลาย เออ)
"แต่ว่าตัวมันเองเนี่ย สามารถคุยกับ API
ของหลายๆ เจ้าได้นะครับ"
"ซึ่งจริงๆมันคุยได้เป็นสิบๆ ตัวเลยนะ
รวมถึง Anthropic กับ Gemini ด้วยนะครับ"
ซึ่งขั้นตอนการ setup เนี่ย
อันนี้ผมเขียนไว้ในเว็บไซต์ผมแล้วนะครับ
"ก็เดี๋ยวท้ายสไลด์เนี่ย หรือว่าจริงๆ
มันจะมีลิงก์เล็กๆ อยู่ตรงเนี้ย"
ก็จะรวบรวมลิงก์ทั้งหมดไว้นะครับ
ก็พอเซ็ตไว้แล้วนะครับ
"เราจะสามารถใช้โปรแกรมเนี้ย
เพื่อคุยกับทั้ง 3 โมเดล"
หรือจะคุยกับทั้ง 3 โมเดลพร้อมๆ กันเลยก็ได้
แล้วตัว Open Web UI เนี่ย
รองรับการทำงานหลาย user ด้วย
ก็คือเราสามารถเซ็ตไว้ให้ใช้งานกันแบบ
แชร์กันใช้ในองค์กรน่ะ
โดยที่ไม่ต้องจ่ายค่า AI เป็นรายหัวได้ด้วยนะครับ
อืม ก็สะดวกมาก
"นอกจาก Open WebUI เนี่ย
จริงๆ ยังมีเครื่องมือ open source"
"แบบเต็มโลก open source เลยอ่ะ
ที่เราสามารถลองไป deploy ใช้เองได้"
ก็แนะนำให้ลองหาเล่นกันดูนะครับ
"เพราะมันจะช่วยให้เราได้ฝึก skill infra
แล้วก็ skill devops ด้วยนะครับ"
"แล้วเราก็จะได้ deploy เครื่องมือที่เราได้ใช้
ในชีวิตประจำวันจริงๆ ด้วยนะครับ"
"ก็ สามารถลองไปหาดูใน GitHub
หรือ Reddit ได้นะครับ"

"จริงๆ มีเครื่องมือ self host อีกตัวนึงนะครับ
ที่อยากจะแนะนำให้รู้จักกัน ชื่อว่า Grist นะครับ"
"ถ้าให้ผมเทียบก็คงคล้ายๆ แบบ Airtable กับ
Google Sheets ผสมกันน่ะครับ"
"เป็น spreadsheet ผสมกับ database อ่า
แต่ว่ามันเป็นแบบที่เรา host เองได้ ฉะนั้น"
"ก็จะไม่ได้แบบมีข้อจำกัด
ว่าห้ามเกิน 1,000 row อะไรแบบเนี้ย"
อ่า แล้วก็มี API ให้ใช้งานด้วยนะครับ
อย่าง project สแกนใบเสร็จก่อนหน้าเนี้ย
"ผมก็ทำ script ไว้ว่าพอเราอัปโหลดไฟล์
ขึ้นโฟลเดอร์นึงใน Google Drive"
ก็ให้ script เนี้ยไปดูดไฟล์ PDF มา
แล้วส่งไปให้โมเดล Gemini ให้จัดการสรุป
แล้วก็ส่งผลลัพธ์ไปไว้บน Grist นะครับ
ฉะนั้นเนี่ย
"ผมพบว่า API ของมันเนี่ย ใช้งานง่ายกว่าทั้ง
Airtable และ Google Sheets เลย"
ฉะนั้นตอนไปเที่ยวรอบล่าสุดเนี่ย
"ผมก็ใช้วิธีนี้แหละ ก็คือสแกนใบเสร็จอัพขึ้น
Google Drive เสร็จแล้วพอ run script เนี่ย"
"ข้อมูลต่างๆ ก็จะมาโผล่ใน Grist
โดยที่เราแทบไม่ต้องพิมพ์เองเลย"
ก็แค่ตรวจทาน นะครับ
ก็ลองไปเล่นกันดูได้นะครับ ชื่อ Grist
โอเค ก็
หลังจากที่ผมได้ลองเล่นโมเดลหลายๆ ตัวเนี่ย
ในหัวข้อถัดไปที่จะถึงนี้นะครับ
"ผมก็จะมาพูดเกี่ยวกับว่า ความคิดเห็นเกี่ยวกับ
โมเดลทั้ง 3 ตัวเป็นยังไงบ้างนะครับ"
"จากที่น่าจะเห็นไปก่อนหน้านี้ คือ Gemini เนี่ย
ผมว่ามันค่อนข้างเก่งด้านภาษามากๆ"
"ถ้าเป็นพวกงานแปล หรือเกลาคำเนี่ย
ผมก็จะลอง Gemini เป็นอันดับแรกเนาะ"
"ส่วนถ้าเป็นเรื่องเกี่ยวกับโค้ดเนี่ย
ผมจะชอบผลลัพธ์ของ Claude มากที่สุด"
ผมว่าผลลัพธ์มันค่อนข้างดีกว่า ChatGPT นะ
"แต่ว่า result เนี่ย มันคือตอนนี้นะ
ในอนาคตอาจจะ outdated นะครับ"
ซึ่งผมใช้ VS Code extension ตัวนึงนะครับ
"ชื่อ Continue.dev ตอนนี้ผมใช้แบบ
ใช้เยอะมากๆ เลย"
"extension ตัวนี้ใช้ฟรี ก็คือ
ไม่ต้องจ่ายค่า subscription"
"แค่เอา API key ของ Claude เนี่ย
มาเสียบเข้า extension เนี้ย"
แล้วเราก็จะจ่ายแค่ค่าโมเดลนะครับ
มันก็ช่วยงานผมหลายๆ อย่างมาก
"อย่างเช่นเวลาผมทำโปรเจกต์
โดยเฉพาะเวลาผม prototype นะ"
บางทีผมอยากทำให้มัน work ก่อน
"ฉะนั้นผมจะเขียนทุกอย่าง
รวมกันเข้าไปในไฟล์เดียวเลย"
"เพราะอะไร? เพราะว่าเวลาเราแก้โค้ดเนี่ย
เราจะได้ไม่ต้องสลับไฟล์ไปมา ใช่ไหม"
ทุกอย่างมันอยู่ในไฟล์เดียวเลยก็ดูแลง่าย
แต่พอโปรเจกต์มันเริ่มใหญ่ครับ แล้วโค้ดเริ่มเยอะ
"ผมก็เริ่มงง เพราะว่าทุกอย่างมันพันกัน
เป็นสปาเก็ตตี้ไปเลย แบบเนี้ย"

ผมก็ใช้ Continue เนี่ยแหละ บอกว่า
"“ช่วยแกะโค้ดที่เกี่ยวกับระบบ PubSub
ออกไปอีก file นึงให้หน่อย”"
อ่า มันก็แบบโอเค จัดให้
แล้วมันก็สร้างไฟล์นี้ให้ครับ
"แล้วมันก็จัดการแก้โค้ดก่อนหน้าเนี้ย
ให้มันไปเรียกฟังก์ชันในไฟล์นั้น"
โอเค แต่บางทีเนี่ย
เราต้อง brief มันเยอะเหมือนกันนะ
คือบางทีเราต้อง brief มันละเอียด
"เพราะว่า เอาจริงๆ มันก็อ่านใจเราไม่ได้
ถึงแม้ว่าเราจะคิดว่าแบบ เออ"
มันใกล้เคียงกับสิ่งที่อ่านใจเราได้มากขนาดนั้น
แต่ว่าบางทีเราก็ต้อง brief มันดีๆ
อ่า ผมพบว่าวิธีเนี้ย เวลาผม refactor อ่ะ
ถึงผมจะต้องเขียน prompt ยาวนะ
"แต่ว่าอย่างน้อยอ่ะ
ผมสามารถโฟกัสกับภาพรวมได้"
"แล้วรายละเอียดปลีกย่อยเนี่ย
ก็ให้ Claude ดูแลให้"
"ทำให้เวลาผม refactor อ่ะ
ผมตาลายน้อยลงมากเลย"

อีกท่านึงที่ผมชอบใช้ ก็คือ
บางทีผมก็ส่งโค้ดจำนวนนึง
แล้วก็ส่งให้มันดูเป็นตัวอย่าง แล้วก็บอกว่า
“ช่วยเขียน development guide ให้หน่อย”
"ถ้ามีคนมาเข้าโปรเจกต์เราเนี่ย
เค้าจะได้รู้ว่าอะไรอยู่ที่ไหน"
"ควรจัดโครงสร้างโค้ดยังไง
เขียนเทสยังไง อะไรแบบเนี้ย"
เราก็จะได้เป็นไฟล์ Readme มาใช่มั้ยครับ
เสร็จแล้วไฟล์ Readme เนี่ยแหละ
ผมก็เอามาใช้ reference ว่า
เวลาขอให้มันเขียนโค้ดเพิ่มเนี่ย ก็บอกว่า
ให้ไปดูไฟล์ Readme ซะ ว่าจะเขียนโค้ดยังไง
"แล้วพอเขียนโค้ดเสร็จ
เราให้มันช่วยเขียนเทสให้ด้วยนะครับ"
"โอเค ฉะนั้นเนี่ย ถ้าเป็นเรื่องโค้ดเนี่ย
ผมจะยกให้ Claude นะครับ"
นอกจากนี้ครับ
"ผมว่า Claude เนี่ย จะตอบคำถามต่างๆ
ได้ค่อนข้างตรงประเด็นมากที่สุดนะครับ"
"เทียบกับ Gemini คือบางทีมันจะมึนๆ บ้าง
ตอบหลงประเด็นบ้างนะครับ"
อืม แต่เท่าที่ผมลองกับเพื่อนนะ
"โดยเฉพาะแบบเวลาปรึกษาปัญหาต่างๆ
ปัญหาชีวิต ปัญหารัก ปัญหางานอะไรพวกเนี้ย"
"บางทีผมก็แบบ เออ
ผมไม่รู้เหมือนกันจะแนะนำยังไง"
มาลองใช้ Gemini ให้คำตอบดู
"ผมพบว่า Gemini เนี่ยค่อนข้างแสดง
ความใส่ใจต่อความรู้สึกได้มากกว่าตัวอื่น"
เผลอๆ เก่งกว่าผมด้วยซ้ำ
"ในขณะที่คำตอบของ Claude เนี่ย
จะค่อนข้างเน้นใช้ตรรกะ"
หรือว่าเป็นเจ้า Logic มากกว่านะครับ

ก็จะมีอีกการทดลองนึงที่ผมเคยทำนะครับ
"คือผมเคยส่งโมเดลพวกเนี้ย
ไปสอบ O-NET ม. 6 นะครับ"
ก็พบว่า Claude เนี่ย ได้คะแนน
เยอะที่สุดนะครับ ก็ ฉะนั้นเนี่ย
ถ้าเรื่องแบบความ…
"คือ ผมไม่รู้ว่าจะเรียกว่าฉลาดดีไหม เพราะว่า
มันก็เป็นแค่ Language Model เนาะ"
แต่ Claude เนี่ย
"มันสามารถแสดงให้เรารู้สึกว่ามันฉลาดได้
มากกว่าเจ้าอื่น เท่าที่ผมลองนะ"

แต่ก็ไม่ใช่ว่า Claude มันจะไม่มีปัญหา
ใช่ไหมครับ
ปัญหาคือเวลาคนใช้กันเยอะๆ เนี่ย
บางที API มันจะล่มครับ
แล้วมันจะ error กลับมาบอกว่า overload
ทำให้ใช้งานไม่ได้ครับ
ส่วน Gemini ก็มีเรื่องน่ารำคาญของมันเหมือนกันครับ
"คือมันจะมี content filter
ที่ค่อนข้าง aggressive เนาะ"
"ถ้าบางทีอ่ะ มันตอบๆ อยู่ แล้วถ้าเกิด จู่ๆ
ไป trigger safety filter มันเมื่อไหร่"
คำตอบจะถูกบล็อกทันทีนะครับ
"ส่วน Claude ก็เช่นกัน บางทีมันก็จะ
ปฏิเสธที่จะทำงานบางอย่างนะครับ"
อย่างผมเคยเอาเนื้อเพลงภาษาอังกฤษมาแปะ
แล้วก็บอกว่า
"“ช่วยเขียนเป็นคำอ่านภาษาไทยให้หน่อย”
คือแบบ “ช่วยทำเป็นคาราโอเกะ” ให้หน่อยอ่ะ"
"Gemini ครับ ไม่ตอบอะไรมาเลย
คือน่าจะโดนบล็อก"
"Claude บอกว่าทำไม่ได้
เพราะว่าเนื้อเพลงเนี่ย ติดลิขสิทธิ์"
ส่วน GPT ครับ
ไม่ปฏิเสธ ทำให้เลยนะครับ
โอเค กลับมาที่หน้านี้ครับ จะเห็นว่า
GPT-4o เนี่ย ด้านซ้ายมันยังโล่งอยู่เลย
คือผมก็ไม่รู้จะว่ายังไงเหมือนกัน เพราะว่า
"ผมก็ยังหาไม่เจอว่ามันมีจุดไหนที่มัน
โดดเด่นกว่าเจ้าอื่นนะครับ"
"ในเชิงความสามารถนะ
คือเอาจริงๆ เนี่ย ผมมองว่า"
"Gemini มันก็เก่งภาษา
Claude ก็เก่งโค้ด"
แต่ GPT-4o เนี่ยสิ
ก็หาจุดเด่นด้านโมเดล ผมยังหาไม่เจอแล้วกัน
"ไม่ใช่ว่ามันไม่มีข้อดีนะ ผมคิดว่า
ทุกอย่างมันมีข้อดี แค่ต้องหาให้เจอ"
อย่างเช่น อย่างน้อยมันไม่ปฏิเสธงานเท่าตัวอื่น
และด้วยความที่มันอยู่มานาน
"API มัน ตอนเนี้ยผมรู้สึกว่ามันเสถียรมากที่สุดเลย
หลังๆ แทบจะไม่เจอมันล่มเลย นะครับ"
"ส่วนพูดถึงสไตล์การเขียนเนาะ
โมเดลแต่ละตัวก็จะมีเอกลักษณ์"
"ซึ่งบางคนเนี่ยก็จะบอกว่า
แต่ละโมเดลเนี้ย มีนิสัยเฉพาะของมัน"
อย่าง Gemini เนี่ย ผมรู้สึกว่ามันใช้ภาษาเก่งดีนะ
แต่บางทีมันชอบใช้ศัพท์แบบเว่อร์วังอลังการไปอ่ะครับ
บางทีผมให้มันช่วยเขียน description ให้วิดีโอ
แล้วบางทีเนี่ย
มันก็จะ generate description มาแบบว่า…
"“พบกับ speaker สุด cool นำเสนอเทคนิคสุดล้ำ
คุณประโยชน์ อะไรต่างๆ น่าทึ่งมาก…”"
“ไม่ดูไม่ได้แล้วแกร!”
อะไรแบบเนี้ย
ผมต้องเขียนคำสั่งเพื่อเบรกมัน
บอกว่าแบบ เฮ้ย ใจร่มๆ หน่อย
"ไม่ต้องทำเหมือนว่าทุกอย่างมัน
น่าตื่นเต้นขนาดนั้นก็ได้ นะครับ"
ส่วน Claude นะครับ
"เวลาคุยกับมันน่ะ ผมรู้สึกว่า
เหมือนคุยกับเพื่อนที่เค้าจริงจังตลอดเวลา"
"เวลาผมพิมพ์ไปหนึ่งประโยค
มันจะตอบมาหนึ่งเรียงความ"
อ่า ครับ
ส่วน GPT-4o ก็ ผมว่ามันก็ balance ดีนะครับ
ก็ประมาณนี้แล้วกัน
ก็ อันนี้คือความเห็นของผมเกี่ยวกับ 3 โมเดลนี้
แต่ จะมีอีกโมเดลนึงที่อยากจะพูดถึงครับ
แต่ผมพึ่งได้ลองมันมาไม่ถึงสัปดาห์เลย
ก็เลยไม่สามารถออกความเห็นได้เยอะนะครับ
"ชื่อว่าอะไรอ่ะ Llama Sonar Online
ของ Perplexity นะครับ"
จุดเด่นของมันคือ
ด้วยความที่มันเป็นโมเดลแบบ online เนี่ย
เราสามารถถามคำถามเกี่ยวกับเหตุการณ์ปัจจุบันได้
"ฉะนั้นบางทีเนี่ย อ่านใน feed
แล้วเห็นประเด็นดราม่า"
"หรือเพื่อนพูดถึงเทรนด์อะไรต่างๆ
ที่มันดราม่า แล้วผมไม่ได้ตามข่าวเนี่ย"
"ผมถาม Perplexity ก็มีโอกาสที่จะได้คำตอบ
ที่ทันเหตุการณ์ครับ แล้วจากที่ผมทดสอบดูอ่ะ"
"ข่าวบางข่าวเนี่ย หรือบางเรื่องเนี่ย
ข่าวมันยังออกมาไม่ถึงครึ่งวันด้วยซ้ำ"
มันก็เอามาตอบได้นะครับ
เอาเป็นว่าผมขอไม่ยกตัวอย่างดราม่าละกัน
แต่ว่าระหว่างที่ผมปั่นสไลด์อยู่เนี่ย ผมก็ทดลองดู
พบว่ามีแค่ Perplexity ตัวเดียวเท่านั้น
ที่สามารถตอบได้ว่าหมูเด้งเป็นฮิปโปนะครับ
อ่า ใช่ ตัวอื่นจะไม่รู้ว่าหมูเด้งมันเป็นชื่อ
มันคิดว่าเราสะกดคำว่าหมูแดงผิด

โอเค ก็จะเห็นว่า โมเดลพวกเนี้ย
มีการพัฒนาปรับปรุงอยู่เรื่อยๆนะครับ
"ฉะนั้นก็อยากจะให้ช่วยกันทดลอง
แล้วก็เปรียบเทียบกันเยอะๆ นะครับ"
แล้วก็มาแชร์ use case กัน
อาจจะไม่ต้องทำเป็นงานวิจัยจริงจังก็ได้เนาะ
อย่างก่อนหน้านี้ ผมไป Haidilao กับเพื่อนๆ
แล้วจู่ๆก็สงสัยกันว่า ไอ้ AI model เนี่ย
ตัวไหนจะปรุงน้ำจิ้มได้อร่อยสุด
ผมก็ถามแต่ละตัวเลย
“ขอ 1 สูตร”
แต่ GPT-4o มันให้มา 2
ก็เลยทำ 2
ก็ลองทำแล้วก็ลองชิมแล้วก็รีวิวกันดู
พอชิมเสร็จเพื่อนผมกลับไปบ้าน
เขาไปกดซื้อ Claude Pro 20 เหรียญ
ฉะนั้นเนี่ยแค่นี้ก็เป็น research ได้แล้วเนาะ
เราลองได้หลายอย่างมากเลย
"โอเคครับ เอ่อ กลับมาที่โปรเจกต์
subtitle แบบอัตโนมัติดีกว่า"
"คือมันก็จะมีบริษัทหลายๆ AI เจ้าใช่มั้ย
ที่มีบริการ speech to text ให้ใช้นะครับ"
และแต่ละเจ้าเนี่ย
ก็ต่างพูดเหมือนกันว่า “ของเราดีที่สุด”
ทำไงดี
ใช่ครับ test, research นะครับ
"ผมใช้ 3 นาทีแรกของคลิปวิดีโอนี้นะครับ
เป็นชุดข้อมูลทดสอบนะครับ"
เสร็จแล้วผมก็โยนไปให้โมเดลแต่ละตัวนะครับ
"โยนไปประมาณ 20 กว่าโมเดลเนี่ย
แล้วก็จดคำตอบที่ได้มานะครับ"
"ส่วน ground truth เนี่ย
คือเราก็แกะคำพูดเอานะครับ"

ฉะนั้นเนี่ย เราเริ่มจากเครื่องมือทั่วๆ ไปก่อนนะ
เดี๋ยวเนี้ยเวลาเราไลฟ์ขึ้น Facebook นะ
Facebook มันทำ subtitle ภาษาไทยให้ด้วยใช่มั้ย
แต่สิ่งหนึ่งที่ผมสังเกตคือ
"เวลาโมเดล speech to text เนี่ย
มันสามารถฟังคำภาษาไทยได้"
"มันจะเสียความสามารถ
ในการสะกดคำภาษาต่างประเทศนะครับ"
สะกดคำภาษาอื่นๆ ไม่ค่อยได้เลย เช่น
metric เนี่ย มันก็สะกดเป็น matrix
หรือ LCP เนี่ย ก็สะกดเป็นคำอ่านแบบเนี้ย
หรือคำว่า largest contentful paint เนี่ย
มันก็ข้ามไปเลย ไม่ output อะไรให้เลยนะครับ
เพราะฉะนั้น ก็ยังใช้ไม่ได้นะครับ
"YouTube เนี่ย เมื่อก่อนมันไม่มี
auto-caption ภาษาไทย ตอนนี้มันมีแล้ว"

แต่ว่าอาการหนักพอๆ กันนะครับ
โอเค นอกจากนี้นะครับ
"cloud ยักษ์ใหญ่ 3 เจ้าเนาะ
Azure, AWS, Google Cloud เนี่ย"
ต่างมี speech to text ของตัวเองกันหมดนะครับ
"แต่ก็ไม่มีโมเดลตัวไหนที่สามารถสะกดคำว่า
largest contentful paint ได้ถูกต้องเลย"
"ซักตัวเดียวนะครับ ก็พอเข้าใจได้ เพราะว่า
มันเป็นศัพท์เทคนิคที่เฉพาะทางมากๆ นะครับ"

"ส่วนตัวเลขด้านขวานะครับ
เรียกว่าเป็น word error rate นะครับ"
ก็คือมีคำผิดอยู่กี่เปอร์เซ็นต์นะครับ
ซึ่งยิ่งน้อยยิ่งดี
"อย่าง 20% เนี่ย แปลว่าทุกๆ 5 คำเนี่ย
ก็จะมีคำผิด 1 คำนะครับ"
ซึ่งถ้าผิดเยอะขนาดเนี้ย
ก็ยังเอาไปใช้งานจริงไม่ค่อยได้เท่าไหร่นะครับ
ในปี 2022
"OpenAI เนี่ย ปล่อยโมเดลตัวนึง
ชื่อว่า Whisper นะครับ"
คือ ก่อนหน้าเนี้ย
พวกโมเดล speech to text เจ้าต่างๆ เนี่ย
เหมือนแต่ละภาษา มันก็จะเทรนแยกกัน
แต่ Whisper เนี่ยต่างจากเจ้าอื่นคือ
เค้าเทรนทุกๆ ภาษาพร้อมๆ กัน
แล้วได้มาเป็นไฟล์โมเดลไฟล์เดียว
แถมเป็น open source ด้วย
คือเราโหลดมารันเองในเครื่องเราได้เลย
ไม่ต้องจ่ายตังค์
ซึ่งพอทดลองนะครับ ก็พบว่าดีขึ้นมาก
สะกด largest contentful paint เนี่ย เกือบถูก
word error rate เนี่ย เหลือ 7%
ซึ่งเป็นตัวแรกที่น้อยกว่า 10%
เท่าที่ผมทดลองมานะ อืม
ผมก็เลยลองเอามาทำคลิปดูนะครับ
"ก็พบว่าคลิป 1 ชั่วโมงเนี่ย
จะใช้เวลาประมาณ 4-6 ชั่วโมงนะครับ"

เพราะว่าแบบ word error rate ซัก 7% เนี่ย
มันก็คือ มันก็จะยังมีคำผิดแทบทุกบรรทัดเลย
"แปลว่าเวลาผมรีวิวเนี่ย
ผมก็ต้อง pause แทบทุกบรรทัดเพื่อแก้"
สุดท้ายมันก็เลยไม่ได้ประหยัดเวลาขนาดนั้น
ต่อมาผมก็มาเจอ docs ของ OpenAI ครับ
ที่บอกว่า ถ้าอยากให้คุณภาพดีขึ้นเนี่ย
"ก็ลองเอา output ของ speech to text เอามา
post-process ด้วย large language model ดูสิ"

อ่า ผมเลยลองดูครับ
อันนี้เป็นอีก talk นึงนะครับ
"อันนี้ผมทำ subtitle ให้
เพื่อที่จะลองทดสอบโมเดลนี้ดู"
เพื่อที่จะลองทดสอบ approach นี้ดู
ปัญหาตัวนึงของ Whisper เนี่ยคือ
มันไม่ค่อยคงเส้นคงวาเท่าไหร่ครับ
ไม่ค่อย consistent เนอะ
"บางทีมันก็สะกดคำฝรั่งได้ แต่ จู่ๆ
บางทีมันก็สะกดไม่ได้ซะงั้น"
อย่างอันเนี้ย มันสะกดทุกคำเป็นภาษาไทย
จนอ่านไม่รู้เรื่องเลย
ระหว่างที่อ่านนะครับ
"ให้ลองจินตนาการดูนะ
ว่ามันคือคำว่าอะไรนะครับ"
แล้วเดี๋ยวจะเห็นเฉลย
โอเค ผมก็ลองเอามาใส่ LLM นะ
"ผมก็ต้องใส่ prompt เข้าไปว่า
“ช่วยแก้คำผิดต่างๆ ให้หน่อยนะ”"
แต่จะเห็นว่า prompt ผมเนี่ยมันยังไม่ค่อยเจาะจง
ฉะนั้นมันเลยยังแก้อะไรให้ผมไม่ได้
"ผมก็ต้องใส่ prompt ใส่ตัวอย่าง
ใส่ข้อกำหนดอะไรต่างๆ เพิ่ม"
จนมันเริ่มจับทางได้
ซึ่งจริงๆ prompt เนี่ย
ยาวกว่านี้อีกประมาณ 2-3 เท่านะครับ
แต่พอมันจับทางได้เนี่ย
ผลลัพธ์มันก็จะดีขึ้นเองครับ
"อย่างเช่น ตัวอย่างนี้ครับ
ผมส่งไปให้ Claude นะ"
แล้วพอผมใช้ Claude มันแก้ให้เกือบหมดเลย
มันช่วยแก้ได้เยอะมากๆ นะครับ
แต่ก็ยังมีบางคำที่มันแก้ไม่ได้
ซึ่งตรงเนี้ย ผมก็ต้อง manual เอาเนาะ
แต่ก็จะเห็นว่า
จากเดิมที่ผมต้องแก้ 7 จุด มันเหลือ 2 จุด
แปลว่าก็น่าจะช่วยลดงานได้ค่อนข้างเยอะนะครับ
ผมก็ลองทำ subtitle ด้วยวิธีนี้นะครับ
"ก็พบว่าคลิป 1 ชั่วโมงเนี่ย
จะเหลือใช้เวลาประมาณ 3-4 ชั่วโมงละ"
"ก็แปลว่าอะไร แปลว่าเราประหยัดเวลา
ไปได้ประมาณครึ่งนึงละ"
"แต่ในขณะเดียวกัน เราจะเริ่มมี
ค่าใช้จ่ายด้านการรับโมเดลนะครับ"
"ตอนนั้นเนี่ย ผมก็แบบ
“เออ เราเจอเทคนิคแล้วแหละ”"
ผมก็เตรียมเขียนบทความแชร์เทคนิค
"แต่ผมดันมาเจอสิ่งที่เรียกว่า
“multimodal AI model” ซะก่อน"
"มันคืออะไรครับ? มันคือโมเดลที่
สามารถ process ได้มากกว่า 1 ช่องทาง"
"ก็คือสามารถ process ข้อความและเสียง
พร้อมๆ กันได้นะครับ"
ตอนนั้นเนี่ยผมรู้ว่า Gemini เนี่ยรับไฟล์ภาพได้
"แต่ไม่เคยรู้เลยว่ามันรับไฟล์เสียงได้ด้วย
จนกระทั่งผมไปอ่าน doc มัน"
มันบอกว่าแบบ เออ เราส่งไฟล์เสียงไปให้ได้เลยนะ
อะไรแบบเนี้ย ผมก็ โอ้… ก็ดีนะ ลองดูดีกว่า
ผมก็เลยลองดูครับ
แล้วผมก็ตะลึงมาก ว่า Gemini 1.5 Pro เนี่ย
"มันสามารถสะกดคำต่างๆ
ได้อย่างถูกต้องเกือบหมดเลย"
"และเป็นตัวแรกที่สะกดคำว่า
largest contentful paint ได้ถูกต้อง"
"โดยที่แบบไม่ต้องให้ context
อะไรมันเพิ่มเติมด้วยนะครับ"
word error rate เนี่ย ลดลงเหลือ 2.5% ก็คือ
ลดไป 3 เท่า
แล้วพอผมลองอีกเนี่ย ผมก็พบว่า
"เฮ้ย ไม่ใช่แค่ไฟล์เสียงนิ
ไฟล์วิดีโอมันก็ทำได้ด้วย"
แล้วพอเราส่งไฟล์วิดีโอเข้าไปเนี่ย
มันอ่าน text บนสไลด์
"เพื่อทำให้สามารถถอดความได้
แม่นยำมากขึ้นอีกด้วยนะครับ"
"ฉะนั้นเนี่ย เทคนิคที่ผม research มาก่อนหน้านี้
ก็คือแบบแทบจะล้มกระดานทิ้งครับ"
ต้องรื้อใหม่หมดเลย
"ฉะนั้นเนี่ย takeaway ก็คือช่วงเนี้ย
เทคโนโลยี AI มันเปลี่ยนไปเร็วมากๆ"
มีอะไรใหม่ๆ มาเรื่อยๆ เลย
"ฉะนั้นผลลัพธ์ในสไลด์เนี่ย
ผมก็ไม่รู้ว่ามันจะอยู่ไปได้อีกนานเท่าไหร่เนาะ"

โอเค ทีเนี้ยผมก็คิดว่า
เออ หวานหมูเราละ
เราอัปโหลดไฟล์วิดีโอไปให้ Gemini Pro
บอกว่าช่วยสร้างไฟล์ subtitle มาให้หน่อย
แค่นี้ก็จบใช่มั้ย
แต่ พอลองดูจริงๆครับ
ไม่จบครับ ปัญหาเต็มเลย
หนึ่งก็คือ อ่า เราไม่มีข้อมูลเกี่ยวกับ
timing information นะครับ
"คือ Gemini เนี่ยจะไม่บอกว่าคำไหน
พูดในวินาทีไหนนะครับ"
คือผลลัพธ์มันแม่นยำมากก็จริง
"แต่พอมันไม่มี timing
เราก็เอามาสร้าง subtitle ไม่ได้ ถูกมั้ย"
เทียบกับพวก speech recognition ธรรมดาเนี่ย
อย่างอันเนี้ยผมใช้ Speechmatics นะ
"ที่จะเห็นว่า ถึง word error rate เนี่ย
มันเยอะกว่า 10 เท่า"
เท่า แต่มันบอกเวลาเป็นรายคำได้เลยนะ
"เอาจริงๆ เนี่ย ถ้า Gemini เราขอให้มัน
ช่วยใส่ timestamp ให้ มันก็ทำให้นะ"
แต่มันมั่วหมดเลย
"อย่างที่ 2 ครับ คือ Gemini API เนี่ย
มันมี limit ของมันอยู่"
คือถ้าเราส่งไฟล์วิดีโอที่มันยาวมากๆ เนี่ย
"สักพักมันจะ time out แล้วตอบเป็น
internal error กลับมา"
"แถม output เนี่ย
มัน output ได้แค่ทีละ 8,000 token"
"แปลว่าเราให้มันฟังคลิปยาวๆ
แล้วสรุปสั้นๆ แบบเนี้ยทำได้"
แต่ถ้าเราบอกให้มันถอดคำพูด
ให้มันถอดคำพูดทั้งหมดเนี่ย
เออ มันก็ทำได้เหมือนกัน
แต่มันถอดไปสักพักนึงมันจะตัดจบ
แล้วก็ อีกปัญหาหนึ่งที่เจอ ก็คือ
บางทีมันก็ตัดบรรทัดแปลกๆ
บางทีมันก็ไปตัดบรรทัดกลางประโยค
หรือบางทีมันก็ไม่ตัดบรรทัดให้เลย
"แบบ talk 30 นาที
มันเขียนเป็น paragraph เดียวให้เลย"
"ซึ่งเราก็ต้องมาออกแบบวิธีครับ
ว่าทำยังไงถึงจะแก้ 3 ปัญหานี้ได้"
เรื่องแรกเนี่ย วิดีโอยาวเกินลิมิต ก็อาจจะไม่ยาก
"ก็คือเราก็แบ่งเป็นส่วนย่อยๆ
แล้วก็ค่อยๆ ทำแยกกัน ใช่มั้ย"
แต่ว่าจะแบ่งยังไงอ่ะ
ถ้าเราแบบแบ่งแบบ…ไม่ได้แบ่งแบบดีๆ อ่ะ
"บางทีมันตัดวิดีโอกลางประโยค
result ที่ได้มันก็ไม่ดี ใช่มั้ย"
จากที่ผมศึกษาเนี่ย ทำได้ 2 วิธีหลักๆ
ก็คือวิเคราะห์คลื่นเสียงว่าตรงไหนที่หยุดพูด
กับอีกวิธีนึงก็คือ
"ใช้ speech to text ตัวที่ไม่แม่นยำ
แต่ว่าให้ข้อมูล timing เรามาได้ครับ"
"ซึ่งผมคิดว่า ไอ้ข้อมูล timing เนี่ย
เดี๋ยวมันจะมีประโยชน์"
ผมเลยเลือกใช้ออปชันนี้ก่อนนะครับ
"ผมก็เริ่มจากแปลงไฟล์วิดีโอนะครับ
แปลงเป็นไฟล์เสียงเนาะ"
เสร็จแล้วก็โยนไปให้ Speechmatics นะครับ
พอโยนเสร็จเนี่ย— อ่า Speechmatics เนี่ย
ถึงคำฝรั่งมันจะสะกดไม่ค่อยได้นะ แต่…
ทุกๆ คำเนี่ย มันจะพยายามสะกดเป็นภาษาไทย
"เทียบกับหลายๆ โมเดล ที่
พอเจอคำฝรั่งปุ๊บมันข้ามไปเลย"
"อันเนี้ย เรื่อง timing อ่ะ
ผมให้ Speechmatics เป็นอันดับต้นๆ"
ครับ แล้วก็
ผลลัพธ์ที่ได้ก็จะเป็นหน้าตาแบบเนี้ยครับ
"ก็คือเราจะมี start_time, end_time
แล้วก็มีข้อความเนอะ"
"ซึ่งเราสามารถเอามา analysis ได้
ว่ามีตรงไหนที่หยุดพูดนะครับ"
อันนี้ผมเอาข้อมูลมา visualize นะครับ
"ก็คือ talk ประมาณ 30 นาทีอ่ะ ผมดูว่า
มีตรงไหนบ้างที่หยุดพูดมากกว่า 1 วินาที"
เสร็จแล้วผมก็หาจุดที่เราจะตัด
ก็คือแบ่งครึ่งตรงกลาง
เสร็จแล้วเราก็ตัดโชะ
แล้วก็ ตัดไปเรื่อยๆ
จนแต่ละคลิปเนี่ย สั้นกว่า 3 นาที
เสร็จแล้วแต่ละคลิปเนี่ย
"เราจะสามารถเอาไป process ได้
แล้วก็ทำแบบ parallel ได้ด้วย"
เพราะว่าตอนเนี้ยแต่ละส่วนมันแยกกันหมดแล้ว
ใช่มั้ยฮะ
โดยแต่ละส่วนเนี่ย ผมก็โยนให้ Gemini ใช่มั้ย

"เราก็จะได้บทถอดคำพูด
ที่ค่อนข้างแม่น แต่ไม่มี timestamp"
แถมสไตล์ก็ อาจจะตัดบรรทัดแปลกๆ
"ซึ่งอันเนี้ยแก้ไม่ยากครับ ก็คือ ก็ส่งอันเนี้ย
ไปให้ Claude บอกว่า ให้ช่วยแก้ให้หน่อย"

และช่วยจัดรูปแบบข้อความอีกที
จริงๆ เนี่ยผมให้มันช่วยแก้คำผิดบางส่วนด้วย
ฉะนั้นเนี่ย ก็จะได้บทถอดคำพูดที่ดีขึ้น
จะเห็นว่าจาก 2.5% เนี่ย ตอนนี้ลดเหลือ 0.6%
แล้วผมก็เอา result จาก Speechmatics เนี่ย
ที่มีข้อมูล timing เนี่ย มาส่งไปให้ GPT-4o
"บอกว่า “ช่วยเอาบทถอดคำพูดจากด้านซ้าย
กับเวลาจากด้านขวามารวมกันหน่อย”"
"อ่า สุดท้ายเราก็จะได้เป็น
คล้ายๆ ไฟล์ subtitle นะครับ"
"ก็คือเรียบร้อยแล้ว 1 ส่วน
เราก็ทำอีก 11 ส่วนที่เหลือนะครับ"
เราก็จะรวมกันได้เป็นไฟล์ subtitle เรียบร้อย
พร้อมรีวิวนะครับ
ฉะนั้นเนี่ย พอผมใช้วิธีเนี้ย
"ก็พบว่ามันเหลือคำผิดน้อยมากๆ
จาก 7% เนี่ย ตอนนี้ลดเหลือไม่ถึง 1%"
ทำให้มันประหยัดเวลาไปได้อีกครึ่งนึงนะครับ
แปลว่าอะไร แปลว่าตอนเนี้ย พอผมรีวิวเนี่ย
"ผมสามารถดูคลิปด้วยสปีด 2x เลย
แล้วพอจุดไหนที่ผมเห็นว่า"
เฮ้ย ยูสะกดผิดนี่นา ก็ค่อย pause แล้วแก้
"ฉะนั้นจากเดิมที่ใช้ 6-8 ชั่วโมงเนี่ย
ลดเวลาไปได้เกือบ 4 เท่าแล้วเนอะ"
แต่ก็จะมีค่าใช้จ่ายที่เพิ่มขึ้นอีกครับ
แต่ก็ถือว่ายังถูก เมื่อเทียบกับ option อื่นเนอะ

ก็จะมีค่าใช้จ่ายเพิ่มขึ้นในการรันโมเดลนะครับ
ซึ่งโค้ดทั้งหมดเนี่ย…
ก็ผมลองมาหลายแบบมาก แล้ว…
โค้ดทั้งหมดเนี่ย ก็จะอยู่บน GitHub นะครับ
ก็เขียนด้วย Node.js TypeScript
"แล้วในนี้ก็จะมีตัวอย่าง prompt
ของแต่ละสเต็ปด้วยนะครับ ก็ไปดูกันได้"
ทีเนี้ยก็จะเห็นว่า พอเราใช้ AI โมเดล…
พอถึงจุดนึงเนี่ย…
ก่อนหน้านี้เราใช้ console ใช่มั้ย
พอถึงจุดนึงเราจะต้องเริ่มเขียนสคริปต์ละ
"ซึ่งเอาจริงๆ เราก็ใช้ Claude
เขียนสคริปต์ให้ก็ทำได้ใช่มั้ย"
เพราะว่าเราดูแค่ word error rate มันไม่พอ
แต่ละ service เนี่ย มันมีจุดดีจุดเด่นต่างกัน
"ซึ่งเขาไม่ได้เขียนใน docs หรอก
เราต้องไปลองเองเราถึงจะเจอ ใช่มั้ย"

พูดถึง TypeScript ครับ
"สมัยก่อนเวลาผมทำโปรเจกต์
ที่ใช้ภาษาไทย TypeScript"
"package.json ผมจะเต็มไปด้วย
dependency ต่างๆ"
"ที่ช่วยทำให้เครื่องมือต่างๆ
มัน support TypeScript ใช่มั้ย"
"แต่เดี๋ยวเนี้ย หลายๆ เครื่องมือ เริ่ม support
TypeScript แบบ built-in แล้วนะครับ"
ทำให้เดี๋ยวเนี้ย package.json ผมสั้นลงเนาะ
"แล้วเมื่อก่อนเนี่ย ผมจะต้องปวดหัว
กับการแก้ไฟล์ tsconfig.json มากๆ"
"แต่เดี๋ยวเนี้ย มันมีแพ็กเกจที่เป็น preset ตั้งต้น
ให้เราสามารถดึงมาใช้ได้แล้วนะครับ"
ก็ทำให้ไฟล์ tsconfig ผมเหลือ 3 บรรทัด
หรือบางทีผมก็ตบเหลือบรรทัดเดียวนะครับ
โอเค มาถึงจุดนี้นะครับ ผมก็ตื่นเต้นมากๆ เลย
"เพราะว่ากว่าจะเอาทุกอย่าง
มาประกอบเข้าด้วยกันเนี่ย"
"คือลองผิดลองถูกมาเยอะมาก
แล้วก็รื้อทิ้งเยอะมากด้วย"
แต่สุดท้ายผมก็ได้แชร์โพสต์บน Facebook ครับ
"เผื่อว่าแบบใครที่เจอปัญหาเดียวกัน
จะได้ลองเอาเทคนิคอันนี้ไปลองใช้ดู"
"ปรากฏว่ามีคนมาคอมเมนต์เยอะเลยว่า
“ลองใช้ตัวนู้นตัวนี้หรือยัง?”"
“อันนี้แม่นมากเลยนะ แม่นจนน่าแปลกใจเลย”
ลองเอาไปเทียบดูได้ ซึ่งผมก็พบว่าแบบ… เอ้อ
พอเราแชร์แล้วเนี่ย
เราพบว่าเราได้พบกับคนที่เจอปัญหาเดียวกัน
แล้วก็แก้วิธีอื่นๆ
แล้วบางทีก็เป็นวิธีที่เราคาดไม่ถึงนะ
หรือบางตัวเราไม่รู้จักด้วยซ้ำนะครับ
หรืออย่างเพจ Mikelopster เนี่ยก็
โพสต์คอนเทนต์แชร์วิธีที่ช่อง Mikelopster เนี่ย
ใช้กับ channel YouTube ของตัวเอง
พอเราแชร์ของเรา แล้วเค้าก็แชร์ของเค้าต่อ
แล้วก็แบบ แชร์ความรู้ของตัวเองอ่ะครับ
"มันก็เลยเหมือนกลายเป็นว่า เราอ่ะ
เป็นฝ่ายที่ได้เรียนรู้จากการแชร์นะครับ"

ฉะนั้นเนี่ย ถ้าผมไม่ได้แชร์เรื่องนี้บน Facebook
ผมก็คงไม่ได้รู้วิธีการแก้ไขปัญหาของคนอื่นๆ
แถมทำให้ได้รู้จักคนใหม่ๆ นะครับ …
แถมได้รู้จักคนใหม่ๆ ที่ชอบลองใช้พวก AI
แล้วก็แชร์ความรู้ต่างๆ กันนะครับ
"โอเค ฉะนั้นพอผมถูกป้ายยามา
ก็ต้องลอง ใช่มั้ย ก็รีเสิร์ชต่อนะครับ"
"ตัวนึงที่มีคนแนะนำมากๆ เนี่ย
มีแนะนำมาอย่างน้อย 3 คนนะ ก็คือ CapCut"
ของ ByteDance เจ้าของ TikTok ใช่มั้ย
หลายคนบอกว่า ถอดคำพูดได้ดีมาก
"อันนี้เท่าที่ผมลองดูนะ
คือเหมือนมันไม่มี API ให้ใช้"
เราก็ต้องโหลดแอป Desktop มาเนอะ
ซึ่งถือว่าดีครับ
ดีกว่าของ Facebook แล้วก็ YouTube
แล้วก็อีกตัวนึงครับ
เป็นโมเดลของ iApp นะครับ
"เป็นโมเดลสัญชาติไทย แล้วก็มีเว็บให้ใช้ฟรีด้วย
แล้วแบบใช้สะดวกมากเลย"

"คือเราอัปโหลดไฟล์วิดีโอไปเนี่ย
แล้วเดี๋ยวมันส่งไฟล์ SRT กลับมาให้เลย"
คือแบบ automatic มากๆ
"ตอนที่ผมทดสอบเนี่ย
word error rate จะอยู่ที่ประมาณ 18%"
แต่เดือนที่แล้วครับ เดือนกันยายน
"เขาบอกว่าเขาเพิ่งปล่อย
ตัวโมเดล Pro ออกมานะครับ"
โอเค ผมก็ลองดู เหลือ 3.5% ครับ ซึ่งน้อยมาก
"แถมเป็นโมเดลภาษาไทยด้วย
แถมให้ข้อมูล timestamp ได้ด้วย"
แปลว่าไอ้ที่ผมลองมาก่อนหน้านี้ก็…
…ใช่มั้ย
ก็เตรียมรื้อนะครับ
(ไม่ทันครับ ไม่ทัน ขอโทษครับ)

(ขอเพิ่มนิดนึงนะครับ)
โอเค ก็จะเห็นว่า
วงการเนี้ย อะไรต่างๆ มันไปเร็วมากๆ นะครับ
เทคนิคต่างๆ เนี่ย outdated เร็วมากนะ
"แต่บทเรียนและประสบการณ์เนี่ยแหละ
ผมคิดว่ามันติดตัวเราไปนะครับ"
"เวลาคนถามเราจะได้บอกได้ว่า
ตัวเนี้ยมีข้อดีข้อเสียยังไง"
ซึ่งมันยากมากที่เราจะ list ออกมาให้หมดอ่ะ
มัน เออ ประมาณนั้นล่ะครับ…
ผมก็เอาลองเอา ตัว iApp ASR Pro มาใช้ดูนะ
"ก็ใช้เวลาประมาณ 1-3 ชั่วโมง
ก็คือใช้เวลารีวิวเยอะขึ้นนิดหน่อยเพราะว่า"
word error rate มันก็ยังสูงกว่า Gemini
"แต่มันสะดวกขึ้นเยอะ เพราะว่า ระบบต่างๆ มัน
automatic พอสมควรเลย"
คือมี timestamp มีอะไรพวกเนี้ย
"ผมไม่ต้องเอาไปโยนเข้าโมเดลนึง
แล้วก็เอามา…อะไรแบบเนี้ย…มารวมกัน"
ฉะนั้นเนี่ย ถ้ามันง่ายขึ้นมากเลย
แถมราคาก็ค่อนข้างโอเคมากๆ ด้วยนะครับ
"ซึ่งถ้าผมเอามาผ่าน
large language model อีกรอบเนี่ย"
มันก็จะยิ่งลด word error rate ไปได้อีกนะครับ
แต่ขั้นตอนกับราคามันก็อาจจะเยอะขึ้นหน่อย
อ่า ฉะนั้นทุกอย่างมันไปเร็วมาก
"แล้วก็เดี๋ยวก็คงจะมี attempt 5, attempt 6
ต่อไปในอนาคตนะครับ"
โอเค ทีเนี้ยพอเรารู้แล้วว่า
"เรามีหนทางที่จะสามารถทำ subtitle
ให้กับทุกวิดีโอในอนาคตเนี่ย"
ก็โอเค เราลองทำหน้าเว็บดูบ้าง
"ซึ่งส่วนตัวเนี่ย ผมห่วยมาก
เวลาออกแบบ UI UX เนี่ย"
เข้าขั้นห่วยเลย เวลาผมต้องทำ UI เนี่ย
ผมมักจะใช้ของสำเร็จรูป เช่น ใช้ Bootstrap นะ
แต่เดี๋ยวเนี้ยมันจะมีเครื่องมือ AI
"เช่น V0.dev ผมว่าหลายๆ คน
น่าจะเคยได้ยินแล้วล่ะ"
"ก็อันนี้ก็คือ prompt ที่ผมเขียนไปเนาะ
แล้วก็จะได้หน้าวิดีโอแบบนี้มา"
ผมก็ใช้เป็นต้นแบบในการ implement ครับ
"แต่บางทีเนี่ย เราต้อง brief มันละเอียดนิดนึง
ถึงจะได้ผลลัพธ์ที่น่าพอใจนะครับ"
อันนี้ก็คือ prompt ที่ผมใช้เนาะ
"โอเค พอผมทำซับมาเรื่อยๆ
มีหน้าเว็บวิดีโอเรียบร้อยแล้ว"
ตอนเนี้ยกลายเป็นว่า จุดที่กินเวลาผมมากที่สุดคือ
การรีวิวแต่ละวิดีโอ แล้วก็การแก้ไข subtitle เนาะ
เพราะมันยังเป็น process ที่มันต้อง manual อยู่อ่ะ
ผมเลยตัดสินใจว่า
"โอเค ผมต้องสร้างโปรแกรม
แก้ subtitle ของตัวเองแล้วแหละ"
แต่ผมไม่อยากเสียเวลามาทำ backend มากนัก
"อยากจะโฟกัสกับการทำเครื่องมือ
ให้มันใช้สะดวกขึ้นนะครับ"
"ผมก็ไปพบว่า มันมีสิ่งหนึ่งที่เรียกว่า
Google Apps Script อยู่"
"แล้วเวลาเปิด Google Sheet เนี่ย
มันจะมี extension แล้วมีเมนู Apps Script"
"ทำให้เราสามารถเขียน JavaScript
เพื่อต่อเติมตัวแอป Google Sheet ได้นะครับ"
เนี่ยผมก็เพิ่มเมนูใหม่เข้าไปใน Google Sheets
"แล้วก็อันนี้ก็คือผมก็สามารถทำ subtitle
ใน Google Sheet ได้แล้วครับ"
(วิดีโอมันเล่นมั้ยนะ…)
"อ่า เนี่ยครับ อันนี้คือตัวอย่าง
ที่ผมแก้ subtitle นะครับ"
"อันนี้ผม speed up ให้ดู
แต่ก็จะเห็นว่าพอผมแก้ในด้านขวาเนี่ย"
มันก็จะไปอัปเดตข้อมูลในด้านซ้ายนะครับ
แปลว่าเราไม่ต้องเขียน backend เองเลย
แค่ให้มันคุยกับ Google Sheet ให้รู้เรื่องนะครับ
ก็ไม่ต้องห่วงเรื่อง import export อะไรแบบเนี้ย
อีกอย่างนึงที่ชอบมากๆ คือ
"พวกโปรแกรม Google Sheets และ Excel
มันทำงานกับข้อมูลรูปแบบเป็น TSV"
"คือถ้าผม copy ตารางออกมาเนี่ย
แล้วเอามาแปะเป็นข้อความเนี่ย"
เราจะพบว่า format มันเป็น format TSV นะครับ
ก็คือแต่ละบรรทัดเนี่ย ก็คือหนึ่ง row
"แล้วก็ แต่ละคอลัมน์เนี่ย
ก็จะด้วยเครื่องหมาย tab (\t)"
ผมสามารถเขียนโปรแกรมแบบง่ายๆ
ให้ process ข้อมูล ที่มีลักษณะเนี้ย
แล้วผมก็ copy กลับมา paste ได้เลย
"ฉะนั้น เวลาเรา import/export ข้อมูลเนี่ย
ผมก็จะชอบใช้ TSV เป็น format กลาง"
ในการแก้ไขข้อมูลเนาะ
ฉะนั้นเนี่ย พอผมทำเครื่องมือใช้เองเนี่ย
ผมสามารถต่อเติมให้มันใช้งานได้สะดวกขึ้นเรื่อยๆ
"ผมก็ใช้ตัวแก้ไข subtitle ตัวเองเนี่ย
ใช้ไปประมาณ 20 วิดีโอได้แล้ว"
แล้วแต่ละครั้งเนี่ย
ผมก็จะเจอจุดเล็กๆ
"ที่เราสามารถทำให้เครื่องมือ
มันใช้สะดวกมากขึ้นได้นะครับ"
แล้วก็เวลาเราทำเครื่องมือใช้เองเนี่ย
บางทีมันก็ overkill นะที่เราจะเริ่มใหม่ตั้งแต่ศูนย์
"ฉะนั้นบางทีเนี่ย เราเขียนโค้ดเรา
ให้ไปเกาะกับโปรแกรมอื่น"
บางทีมันก็จะประหยัดเวลากว่านะครับ
"เรื่องสุดท้ายที่อยากจะมาแชร์นะ
ก็คือบางทีเนี่ย ผมอยากทำโปรเจกต์"
ทำ library TypeScript
"ไว้เพื่อ reuse กับโปรเจกต์ต่างๆ
โดยใช้ภาษา TypeScript เนาะ"
"ซึ่งถ้าใครเคยทำ library ด้วย TypeScript
ก็จะรู้ว่า มันต้องใช้เครื่องมือหลากหลายมาก"
กว่าจะ publish library ตัวนึงได้
"ไหนจะเครื่องมือ test
เครื่องมือ format code"
"เครื่องมือ check code
หรือทำ documentation เนี่ย"
โอ้โห เครื่องมือเต็มไปหมดเลย
ก็เลยจะมาแนะนำให้รู้จักกับ JSR
พอใช้ JSR เนี่ย
ผมแทบไม่ต้องติดตั้ง build tool อะไรเพิ่มเลย
คือเวลา publish package เนี่ย
ผมก็ publish ไฟล์ .ts ไปที่ service ของ JSR เลย
แล้ว JSR มันทำอะไรนะครับ
มันจะสร้างหน้าเว็บให้ scope ของเรานะครับ
"แล้วแต่ละ package เนี่ย ก็สามารถ
install ด้วย NPM ได้"
"ก็คือ service ของ JSR มันจะแปลงโค้ด
TypeScript ที่เรา publish ขึ้นไปอ่ะ"
ให้กลายเป็น JavaScript ให้เองเลย
"แถมมีขั้นตอนการติดตั้งอยู่ด้านขวาเลย
ก็คือไม่ต้องมาเขียนใน README มีเอง"

"พวกของต่างๆ ที่เรา export มาเนี่ย
ก็จะมี documentation ให้อ่านนะครับ"
ก็คือทำไว้ได้ดีมาก
ก็คือเป็นเครื่องมือ ที่ครบเครื่องเลย
ก็ publish ไฟล์ ts ไป ก็จบเลยนะครับ
"โอเค ก็ทั้งหมดเนี่ย ก็คือเรื่อง
ที่ผมอยากจะแชร์ในปีนี้ครับ"
ก็หวังว่าจะเป็นประโยชน์ครับ
แต่ก็ไม่รู้จะสรุป session นี้ยังไงเหมือนกันเนาะ
"แต่เอาเป็นว่า ตอนเนี้ยเรามีวิดีโอ
เรามีวิธีสร้าง subtitle แล้ว"
"ก่อนที่เราจะอัปขึ้น YouTube
เราต้องทำอะไรเนาะ"
"เราต้องเขียน description
แล้วก็ทำ chapter ใช่ไหม"
"มาถึงจุดเนี้ย ผมเชื่อว่าทุกๆ คนน่าจะเดาออก
ว่าผมจะทำยังไงต่อนะครับ"
ก็ ใน wiki ของ Creatorsgarten เนี่ย
มันจะมีรายละเอียดเกี่ยวกับขั้นตอนต่างๆ นะครับ
"ไปดูได้ รวมถึงมี prompt และโค้ดทั้งหมด
ที่เราใช้ด้วย ในการ generate นะครับ"
"จะเห็นว่า prompt ต่างๆ เนี่ย
มันยาวมาก เพราะว่าอะไร?"
เพราะว่า… คือ…
คือแบบนี้ครับ
"ผมเห็นว่าบางคนเนี่ย เวลาคุยกับ AI เนี่ย
เขาจะชอบคุยแบบนี้ ก็คือ"

ขอให้มันสร้างอะไรสักอย่างให้
"แต่พอผลลัพธ์ไม่เป็นที่น่าพอใจ
ก็คุยกับมันต่อ “ช่วยแก้นี้หน่อยนะ”"
"ผลลัพธ์ก็ดีขึ้น แต่ถ้ายังไม่ดีพอ
เราก็คุยต่อ จน มันดี ใช่มั้ย"

ซึ่ง ผมว่ามันก็โอเคครับ
เรียกว่าเป็นการคุยแบบ multi-turn
ข้อดีคือมันง่ายแล้วมันเป็นธรรมชาติ ใช่มั้ย
"แต่ข้อเสียคือ ถ้าเราต้องการจะทำแบบเดิม
กับเนื้อหาอื่นเนี่ย เรามี 2 ทางเลือกคือ"
"ถ้าเราเริ่มใหม่ เราก็ต้องเริ่มจากศูนย์
แล้วก็ค่อยๆ สอนมันใหม่ ใช่มั้ย"
หรือไม่ เราก็ต้องต่อบทสนทนาเนี้ย ก็คือ
"เอาที่คุยกันเนี่ย
แล้วก็เอาคอนเทนต์ใหม่โปะเข้าไป"
กลายเป็นว่าอะไร?
กลายเป็นว่า บทสนทนาเราก็จะยาวขึ้น
แล้วพอบทสนทนายาวขึ้น token มันก็จะเยอะขึ้น
แล้วมันก็จะแพงขึ้นเรื่อยๆ
"ผมเลยแนะนำว่า ถ้าเป็น task ไหน
ที่เรา ต้องใช้กับคอนเทนต์หลายๆชิ้น"
อ่า ผมจะแนะนำให้ทำแบบ single-turn มากกว่า
"คือถ้า AI เนี่ย มันไม่ให้ผลลัพธ์ที่เราต้องการ
เรากลับไปแก้ prompt ให้มันยาวขึ้น"
"เพิ่มข้อกำหนด เพิ่มตัวอย่าง
ลองรันใหม่ อ่า ก็คือแก้ brief อ่ะ"
จนกระทั่งเราได้ผลลัพธ์ที่น่าพอใจนะครับ
"ซึ่ง prompt ตัวเนี้ย เรารียูสได้
กับคอนเทนต์อื่นได้นะครับ"
ก็เลยเป็นเหตุผลที่ prompt มันยาว
ผมก็เลยลองเอาสคริปต์ของหัวข้อวันเนี้ย
"ส่งให้ Gemini ให้มันช่วยแบ่งตอน
แล้วก็เขียน description ให้นะครับ"
และผลลัพธ์ที่ได้ออกมาก็ตามนี้นะครับ
"มันจะมีจุดผิดพลาดอยู่ประมาณ 2 จุด
ซึ่งผมแก้ไปแล้วเนาะ ก็นั่นแหละ"
เวลาใช้ AI ต้องตรวจทานผลลัพธ์มันด้วยนะครับ
"ส่วนลิงก์และแหล่งอ้างอิงต่างๆนะครับ
ผมจะใส่ไว้ที่ลิงก์นี้นะครับ"
"แล้วก็ channel Creatorsgarden
บน YouTube นะครับ"
"นอกจากทั้งหมดที่เราเล่ามาเนี่ย
เรายังมีการเซ็ทระบบเพื่อให้ทีมงานเราเนี่ย"
"สามารถดูแล channel YouTube
กันบน GitHub ได้ด้วยนะครับ"
"ก็คือถ้าใครอยากจะเปลี่ยนรูป
เปลี่ยน thumbnail เปลี่ยน description"
แก้ไขข้อมูล metadata อะไรต่างๆ เนี่ย
คือ submit PR มาได้เลย แล้วพอ merge เนี่ย
"มันก็จะมี automation ที่ไปอัพเดทเนื้อหา
บน channel YouTube ให้อีกทีนะครับ"
ซึ่งถ้าใครสนใจว่ารายละเอียดเป็นยังไงนะครับ
"ก็เรามี talk เกี่ยวกับเรื่องนี้อยู่นะครับ
ก็ไปหาดูหรือหาอ่านดูได้นะครับ"
"แล้วก็ฝาก subscribe ช่อง
Creatorsgarden กันด้วยนะครับ"
โอเค สำหรับวันนี้ขอบคุณมากครับ

ขอบคุณพี่ไทมากๆ เลยนะครับ
สุดยอด
กลับไป ทุกคนมีไฟละ
จะกลับไปทำ tools ของตัวเองนะครับ
"จริงๆ เนี่ย single-turn ผมใช้อยู่
กับ OpenAI เหมือนกัน"
"OpenAI หรือตัว ChatGPT ถ้าเกิดไปเช็ค
มันจะมีพวก personalized prompt อยู่"
ผมไปทำเหมือนเป็น command อ่ะครับ
"ว่าถ้าเกิดเขียนมาประมาณเนี้ย
ให้เหมือนเป็นการตรวจแกรมม่า"
ใดๆ ไปลองดูได้
อ๊ะ! อันนี้คืออะไรอ่ะ?
เปล่าครับ ผมอัดคลิปของผมเอง
อ๋อ อัดคลิปเหรอ อ๋อ สวัสดีครับ